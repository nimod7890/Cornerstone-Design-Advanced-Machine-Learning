{"cells":[{"cell_type":"markdown","metadata":{"id":"meGL-F1KzXS7"},"source":["# Tutorial 4: PyTorch Tensor, Module"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VirmyCIqzXTC"},"outputs":[],"source":["import math\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","import matplotlib.colors as mplcolors\n","from tqdm import tqdm\n","from torch.utils.data import DataLoader\n","from tabulate import tabulate"]},{"cell_type":"markdown","metadata":{"id":"7pEfzNsSzXTF"},"source":["### Set seed"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bwvoF47JzXTG"},"outputs":[],"source":["np.random.seed(444)\n","torch.random.manual_seed(444)"]},{"cell_type":"markdown","metadata":{"id":"Y4BjwJeWzXTH"},"source":["# 1. Tensor basics\n","\n","Tensors are similar to Numpy's ndarays, except that tensors can run on GPUs or other specialized hardware to accelerate computing."]},{"cell_type":"markdown","metadata":{"id":"WPnyJV74zXTI"},"source":["### 1.1. Tensor initialization"]},{"cell_type":"markdown","metadata":{"id":"q-27eXwyzXTJ"},"source":["Tensors can be created directly from data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AUkpnguwzXTK"},"outputs":[],"source":["data = [[1, 2], [3, 4]]\n","tensor_from_data = torch.tensor(data)\n","print(type(tensor_from_data))\n","print(tensor_from_data)"]},{"cell_type":"markdown","metadata":{"id":"85J1Ac0QzXTL"},"source":["Tensors can be created from Numpy arrays (and vice versa)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Va_1lKhUzXTL"},"outputs":[],"source":["numpy_data = np.array(data)\n","tensor_from_numpy = torch.from_numpy(numpy_data)\n","print(type(tensor_from_numpy))\n","print(tensor_from_numpy)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TzzGjJVxzXTM"},"outputs":[],"source":["numpy_from_tensor = tensor_from_numpy.numpy()\n","print(type(numpy_from_tensor))\n","print(numpy_from_tensor)"]},{"cell_type":"markdown","metadata":{"id":"hYZYSN1UzXTN"},"source":["Tensors can be created from another tensor."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uhO_QSUQzXTN"},"outputs":[],"source":["tensor_from_tensor1 = torch.ones_like(tensor_from_data)\n","print(f'Ones Tensor: \\n {tensor_from_tensor1}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8LdwZNGYzXTO"},"outputs":[],"source":["tensor_from_tensor2 = torch.rand_like(tensor_from_data, dtype=torch.float64)\n","print(f'Random Tensor: \\n {tensor_from_tensor2}')"]},{"cell_type":"markdown","metadata":{"id":"ELUYeDGDzXTP"},"source":["### 1.2. Tensor attributes"]},{"cell_type":"markdown","metadata":{"id":"OS5hsZHuzXTP"},"source":["Tensor attributes describe their shape, datatype, and the device on which they are stored."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"35Qy2IxSzXTP"},"outputs":[],"source":["tensor = torch.rand(3, 4)\n","\n","print(f\"Shape of tensor: {tensor.shape}\")\n","print(f\"Datatype of tensor: {tensor.dtype}\")\n","print(f\"Device tensor is stored on: {tensor.device}\")"]},{"cell_type":"markdown","metadata":{"id":"SoRCeTM4zXTQ"},"source":["### 1.3. Tensor operations (see [this page](https://pytorch.org/docs/stable/torch.html) for more details)"]},{"cell_type":"markdown","metadata":{"id":"fqten8XOzXTQ"},"source":["Elementwise operations:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2YmBuQnFzXTQ"},"outputs":[],"source":["x = torch.tensor([[1, 2], [3, 4]], dtype=torch.float64)\n","y = torch.tensor([[5, 6], [7, 8]], dtype=torch.float64)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"silGAFo4zXTR"},"outputs":[],"source":["# elemwise sum\n","print(x + y)\n","print(x.add(y))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8lnakRwFzXTR"},"outputs":[],"source":["# elemwise difference\n","print(x - y)\n","print(x.sub(y))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4HzD1MpUzXTS"},"outputs":[],"source":["# elemwise product\n","print(x * y)\n","print(x.mul(y))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NI1G8LOLzXTT"},"outputs":[],"source":["# elemwise division\n","print(x / y)\n","print(x.divide(y))"]},{"cell_type":"markdown","metadata":{"id":"lwmjAe-KzXTT"},"source":["Matrix operations:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mkzv996ZzXTT"},"outputs":[],"source":["x = torch.tensor([[1, 2], [3, 4]], dtype=torch.float64)\n","y = torch.tensor([[5, 6], [7, 8]], dtype=torch.float64)\n","\n","v = torch.tensor([9, 10], dtype=torch.float64)\n","w = torch.tensor([11, 12], dtype=torch.float64)\n","\n","print(f'x: {x.shape}, y: {y.shape}, v: {v.shape}, w: {w.shape}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_m50RgnSzXTU"},"outputs":[],"source":["# vector-vector product\n","print(v.dot(w))\n","print(torch.dot(v, w))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9BhtBTB_zXTU"},"outputs":[],"source":["# matrix-vector product\n","print(x.matmul(v))\n","# print(torch.mm(x, v)) --> this will raise an error\n","print(torch.matmul(x, v))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iRf8t0yizXTV"},"outputs":[],"source":["# matrix-matrix product\n","print(x.mm(y))\n","print(torch.mm(x, y))\n","print(torch.matmul(x, y))"]},{"cell_type":"markdown","source":["# 2. ```nn.Module```\n","\n","* Base class for all neural network modules.\n","* Your models should also subclass this class.\n"],"metadata":{"id":"SZqOe5msztWW"}},{"cell_type":"markdown","source":["### 2.1. Building MLP and CNN in PyTorch"],"metadata":{"id":"cXejxrAltQ77"}},{"cell_type":"code","source":["class MLP(nn.Module):\n","    def __init__(self):\n","        super(MLP, self).__init__()\n","        self.net = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(in_features=3*32**2, out_features=128),\n","            nn.ReLU(),\n","            nn.Linear(in_features=128, out_features=128),\n","            nn.ReLU(),\n","            nn.Linear(in_features=128, out_features=128),\n","            nn.ReLU(),\n","            nn.Linear(in_features=128, out_features=10)\n","        )\n","    \n","    def forward(self, x):\n","        return self.net(x)"],"metadata":{"id":"E-ZGoOQgt6Zh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        self.net = nn.Sequential(\n","            nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1, padding=0),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0),\n","            nn.ReLU(),\n","            nn.Flatten(),\n","            nn.Linear(in_features=16 * 10**2, out_features=120),\n","            nn.ReLU(),\n","            nn.Linear(in_features=120, out_features=84),\n","            nn.ReLU(),\n","            nn.Linear(in_features=84, out_features=10)\n","        )\n","    \n","    def forward(self, x):\n","        return self.net(x)"],"metadata":{"id":"nNpBVt8etRd6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2.2. Load data (cifar-10)"],"metadata":{"id":"Ojc8VB-4phv_"}},{"cell_type":"code","source":["def get_data_stats(trn_data, tst_data):\n","    # number of img\n","    n_data_trn = len(trn_data)\n","    n_data_tst = len(tst_data)\n","\n","    # img size\n","    size_trn = 'x'.join(map(str, trn_data.data.shape[1:]))\n","    size_tst = 'x'.join(map(str, tst_data.data.shape[1:]))\n","\n","    # mean & std of img\n","    avg_trn = np.mean(trn_data.data, axis=(0, 1, 2))\n","    std_trn = np.std(trn_data.data, axis=(0, 1, 2))\n","\n","    avg_tst = np.mean(tst_data.data, axis=(0, 1, 2))\n","    std_tst = np.std(tst_data.data, axis=(0, 1, 2))\n","\n","    # convert to string\n","    rgb = ['R', 'G', 'B']\n","    ms_trn = ', '.join([f'{c}:{m:.2f}({s:.2f})' for c, m, s in zip(rgb, avg_trn, std_trn)])\n","    ms_tst = ', '.join([f'{c}:{m:.2f}({s:.2f})' for c, m, s in zip(rgb, avg_tst, std_tst)])\n","\n","    # number of class & number of img per class\n","    n_class_trn, n_img_class_trn = np.unique(trn_data.targets, return_counts=True)\n","    n_class_tst, n_img_class_tst = np.unique(tst_data.targets, return_counts=True)\n","\n","    n_class_trn = len(n_class_trn)\n","    n_class_tst = len(n_class_tst)\n","\n","    # convert to string\n","    n_img_class_trn = ', '.join([f'{i}: {n:4d}' for i, n in enumerate(n_img_class_trn)])\n","    n_img_class_tst = ', '.join([f'{i}: {n:4d}' for i, n in enumerate(n_img_class_tst)])\n","\n","    # aggregate\n","    data_stats = [['Train', n_data_trn, size_trn, ms_trn, n_class_trn, n_img_class_trn],\n","                  ['Test', n_data_tst, size_tst, ms_tst, n_class_tst, n_img_class_tst]]\n","    \n","    return data_stats\n","\n","\n","def random_indices(n_class_train, train_label):\n","    indices = []\n","    for i in range(n_class_train):\n","        idx = np.where(train_label == i)[0]\n","        idx_selected = np.random.choice(idx, size=5)\n","        indices.append(idx_selected)\n","    return np.array(indices).T\n","\n","\n","def plot_random_images(train_img, train_label, n_class_train):\n","    # select random indices\n","    indices = random_indices(n_class_train, np.array(train_label))\n","\n","    # nrow & ncol of figure\n","    nrow, ncol = indices.shape\n","\n","    # plot\n","    fig, axs = plt.subplots(nrow, ncol, figsize=(15, 5), constrained_layout=True)\n","    for i in range(nrow):\n","        for j in range(ncol):\n","            img = train_img[indices[i][j]]\n","            axs[i][j].imshow(img, vmin=0, vmax=255)\n","            axs[i][j].set_xticks([])\n","            axs[i][j].set_yticks([])"],"metadata":{"id":"DFUnNoWzn10l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# mount drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"Au5CdUocyjMD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# https://pytorch.org/vision/0.9/transforms.html\n","transform = transforms.Compose([transforms.ToTensor()])\n","\n","# https://pytorch.org/vision/stable/datasets.html\n","train_data = torchvision.datasets.CIFAR10(root='/content/drive/MyDrive/ICE3050/dataset', train=True, download=True, transform=transform)\n","test_data = torchvision.datasets.CIFAR10(root='/content/drive/MyDrive/ICE3050/dataset', train=False, download=True, transform=transform)"],"metadata":{"id":"LrbK9exBprqS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_stats = get_data_stats(train_data, test_data)\n","print(tabulate(data_stats, headers=['index', 'n img', 'img size', 'mean & std', 'n class', 'n img per class']))"],"metadata":{"id":"LzkrOyEvrT48"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_random_images(train_data.data, train_data.targets, n_class_train=10)"],"metadata":{"id":"hgvubsVms3aw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2.3. Train model"],"metadata":{"id":"6Vqlxu2LtndV"}},{"cell_type":"code","source":["def train(model, optim, train_data, test_data, epochs, batch_size, lr, momentum):\n","    # set seed\n","    torch.manual_seed(0)\n","\n","    # ship dataset to dataloader \n","    # https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\n","    train_loader = DataLoader(train_data, batch_size, shuffle=True, num_workers=2)\n","    valid_loader = DataLoader(test_data, batch_size, shuffle=False, num_workers=2)\n","\n","    # set device\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    if model == 'cnn':\n","      model = CNN().to(device)\n","    elif model == 'mlp':\n","      model = MLP().to(device)\n","    else:\n","      raise NotImplementedError\n","\n","    # optimizer\n","    # https://pytorch.org/docs/stable/optim.html\n","    if optim == 'sgd':\n","      optim = torch.optim.SGD(model.parameters(), lr, momentum)\n","    elif optim == 'adam':\n","      optim = torch.optim.Adam(model.parameters(), lr)\n","    else:\n","      raise NotImplementedError\n","\n","    def calc_accuracy(yhat, y):\n","        _, yhat = torch.max(yhat, dim=1)\n","        return (yhat == y).sum().item() / y.size(0)\n","\n","    # loss\n","    loss_fn = nn.CrossEntropyLoss()\n","    eval_fn = calc_accuracy\n","\n","    train_losses, train_accrs = [], []\n","    valid_losses, valid_accrs = [], []\n","\n","    # begin training\n","    for e in range(epochs):\n","        train_loss = 0.\n","        train_accr = 0.\n","        for i, (x, y) in enumerate(tqdm(train_loader)):\n","            x = x.to(device)\n","            y = y.to(device)\n","            yhat = model(x)\n","            loss = loss_fn(yhat, y)\n","            accr = eval_fn(yhat, y)\n","            optim.zero_grad()\n","            loss.backward()\n","            optim.step()\n","            train_loss += loss\n","            train_accr += accr\n","        # save log\n","        train_losses.append(train_loss.item()/(i+1))\n","        train_accrs.append(train_accr/(i+1))\n","        # validation\n","        with torch.no_grad():\n","            valid_loss = 0.\n","            valid_accr = 0.\n","            for i, (x, y) in enumerate(tqdm(valid_loader)):\n","                x = x.to(device)\n","                y = y.to(device)\n","                yhat = model(x)\n","                loss = loss_fn(yhat, y)\n","                accr = eval_fn(yhat, y)\n","                valid_loss += loss\n","                valid_accr += accr\n","            # save log\n","            valid_losses.append(valid_loss.item()/(i+1))\n","            valid_accrs.append(valid_accr/(i+1))\n","        # print log\n","        log = f'Epoch: {e+1}/{epochs}, ' + \\\n","            f'loss (train): {train_losses[-1]:.4f}, ' + \\\n","            f'accuracy (train): {train_accrs[-1]*100:2.2f}%, ' + \\\n","            f'loss (valid): {valid_losses[-1]:.4f}, ' + \\\n","            f'accuracy (valid): {valid_accrs[-1]*100:2.2f}%'\n","        print(log)\n","    print('Done.', end='\\n\\n')\n","\n","    return train_losses, train_accrs, valid_losses, valid_accrs"],"metadata":{"id":"cVXX_zNUs6li"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_loss, train_accr, valid_loss, valid_accr = train('mlp', 'sgd', train_data, test_data, 5, 4, 0.001, 0.9)"],"metadata":{"id":"GJXNUsSsuEz_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_loss2, train_accr2, valid_loss2, valid_accr2 = train('cnn', 'sgd', train_data, test_data, 5, 4, 0.001, 0.9)"],"metadata":{"id":"L7cfRKAXuftg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["drive.flush_and_unmount()"],"metadata":{"id":"ZNiQC0cczAiA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3. Optional readings\n","* [What is torch.nn really?](https://pytorch.org/tutorials/beginner/nn_tutorial.html)\n","* [How PyTorch Module works inside](https://teamdable.github.io/techblog/PyTorch-Module)"],"metadata":{"id":"ml8uV1KyxoqU"}},{"cell_type":"code","source":[],"metadata":{"id":"8n-gZXkmxeqt"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.7.13 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.13"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"}},"colab":{"provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}