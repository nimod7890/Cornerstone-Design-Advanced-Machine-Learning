{"cells":[{"cell_type":"markdown","source":["# import"],"metadata":{"id":"bLfpR4UFbEC_"}},{"cell_type":"code","execution_count":125,"metadata":{"id":"y0Z6Dt1A5hg6","executionInfo":{"status":"ok","timestamp":1669016335038,"user_tz":-540,"elapsed":8,"user":{"displayName":"김보민","userId":"10678150510375534256"}}},"outputs":[],"source":["from __future__ import unicode_literals, print_function, division\n","from io import open\n","import glob\n","import os\n","import unicodedata\n","import string\n","import random\n","import torch\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import numpy as np"]},{"cell_type":"code","execution_count":126,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3912,"status":"ok","timestamp":1669016338942,"user":{"displayName":"김보민","userId":"10678150510375534256"},"user_tz":-540},"id":"qtFbuKJb6anU","outputId":"0ffd791b-fa75-47eb-df75-5674ef8424cd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# mount drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":127,"metadata":{"id":"zFMSCTOENYtk","executionInfo":{"status":"ok","timestamp":1669016338942,"user_tz":-540,"elapsed":39,"user":{"displayName":"김보민","userId":"10678150510375534256"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bc541424-44ee-483f-8685-9742c86ded83"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":127}],"source":["# set device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"]},{"cell_type":"markdown","metadata":{"id":"u_u72FI88G-G"},"source":["# 0. Overview"]},{"cell_type":"markdown","metadata":{"id":"ZNJRMv_87CoQ"},"source":["* In the last tutorial we used a RNN to classify names into their language of origin. This time we'll turn around and generate names from languages.\n","* The big difference is instead of predicting a category after reading in all the letters of a name, we input a cetegory and output one letter at a time. Recurrently predicting characters to form language (this could also be done with words or other higher order constructs) is often referred to as a \"language model\"."]},{"cell_type":"markdown","metadata":{"id":"a--P5LVo59px"},"source":["# 1. Preparing the Data"]},{"cell_type":"code","execution_count":128,"metadata":{"id":"02rfwqdT55QR","executionInfo":{"status":"ok","timestamp":1669016338942,"user_tz":-540,"elapsed":31,"user":{"displayName":"김보민","userId":"10678150510375534256"}}},"outputs":[],"source":["def find_files(path):\n","    return glob.glob(path)\n","\n","all_letters = string.ascii_letters + \" .,;'\"\n","n_letters = len(all_letters)\n","# print(all_letters)\n","# print(n_letters)\n","# Turn a Unicode string to plain ASCII, thanks to\n","# https://stackoverflow.com/a/518232/2809427\n","def unicode_to_ascii(s):\n","    return ''.join(\n","        c for c in unicodedata.normalize('NFD', s) \n","        if unicodedata.category(c) != 'Mn' and c in all_letters\n","    )\n","\n","# Read a file and split into lines\n","def read_lines(fname):\n","    lines = open(fname, encoding='utf-8').read().strip().split('\\n')\n","    return [unicode_to_ascii(line) for line in lines]"]},{"cell_type":"code","execution_count":129,"metadata":{"id":"taET1tsV6GQw","executionInfo":{"status":"ok","timestamp":1669016338943,"user_tz":-540,"elapsed":31,"user":{"displayName":"김보민","userId":"10678150510375534256"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"80fb49cb-48b3-4b26-d6bb-ad95a13db305"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["18"]},"metadata":{},"execution_count":129}],"source":["# Build the category_lines dictionary, a list of names per language\n","category_lines = {}\n","all_categories = []\n","\n","# Read a file and split into lines\n","for fname in find_files('/content/drive/MyDrive/ICE3050/dataset/names/*.txt'):\n","    category = os.path.splitext(os.path.basename(fname))[0]\n","    all_categories.append(category) # country name\n","    lines = read_lines(fname)\n","    category_lines[category] = lines\n","\n","n_categories = len(all_categories)\n","n_categories"]},{"cell_type":"code","execution_count":130,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1669016338943,"user":{"displayName":"김보민","userId":"10678150510375534256"},"user_tz":-540},"id":"0vWnGuxl6JfP","outputId":"1b0fffed-da51-4bcd-cc1c-f8462bfba24c"},"outputs":[{"output_type":"stream","name":"stdout","text":["['Polish', 'Irish', 'Greek', 'French', 'Korean']\n","['Abbas', 'Abbey', 'Abbott', 'Abdi', 'Abel']\n"]}],"source":["print(all_categories[:5])\n","print(category_lines['English'][:5])"]},{"cell_type":"markdown","metadata":{"id":"SRVZr6wT60aF"},"source":["# 2. Creating the Network"]},{"cell_type":"markdown","metadata":{"id":"N8zKR57m9tfs"},"source":["* This network extends the last tutorial's RNN with an extra argument for the category tensor, which is concatenated along with the otehrs. The category tensor is a one-hot vector just like the letter input.\n","\n","* We will interpret the output as the probability of the next letter. When sampling, the most liekly output letter is used as the next input letter.\n","\n","![link text](https://i.imgur.com/jzVrf7f.png)"]},{"cell_type":"markdown","source":["마지막 hidden -> out combined 으로 가는 연결 선은 잘모 ㅅ그리심ㅁ"],"metadata":{"id":"fgj6tq2UIWOw"}},{"cell_type":"markdown","source":["* **Q.1**: 3 points (1 point, 2 points)"],"metadata":{"id":"XGJVg3BTPMHw"}},{"cell_type":"code","execution_count":131,"metadata":{"id":"RlEqb_D06Kco","executionInfo":{"status":"ok","timestamp":1669016338944,"user_tz":-540,"elapsed":19,"user":{"displayName":"김보민","userId":"10678150510375534256"}}},"outputs":[],"source":["class RNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, output_size):\n","        ############################################################################\n","        # TODO: implement an __init__ function of RNN. This class has five member  #\n","        # variables: hidden_size, num_layers, rnn, fc, and dropout, Assign suitable#\n","        # values to all of those variables. IMPORTANT: (1) do \"not\" use nn.Linear  #\n","        # to implement self.rnn, please use nn.RNN instead. (2) a probability of an#\n","        # element to be zeroed (the first argument of Dropout layer) is 0.1.       #\n","        ############################################################################\n","        super(RNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.rnn = nn.RNN(input_size,hidden_size,num_layers,batch_first=True) #linear 사용하지 말고 내장 rnn\n","        self.fc = nn.Linear(hidden_size,output_size)\n","        self.dropout = nn.Dropout(p=0.1) #nn.Module dropout -> dropout 비욜 0.1로 \n","        # ********** END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE) *********** #\n","\n","    def forward(self, category, input, hidden=None):\n","        ############################################################################\n","        # TODO: implement a forward function. This function outputs two tensors    #\n","        # (output, hidden), where the first one is the final output of self.fc()   #\n","        # and the second one is the final hidden state of self.rnn(). You're answer#\n","        # MUST include all of the following:                                       #\n","        #     (1) initialize hidden state, if hidden is None.                      #\n","        #     (2) concatenate two input tensors (category, input).                 #\n","        #     (3) forward propagate through self.rnn (nn.RNN module).              #\n","        #     (4) reshape the output to fit self.fc (nn.Linear module).            #\n","        #     (5) forward propagate through self.fc (nn.Linear module).            #\n","        #         (the input to self.fc is the output of the self.nn)              #\n","        #     (6) dropout some elements of the output of self.fc()                 #\n","        ############################################################################\n","\n","        if hidden is None:\n","            hidden = self._init_hidden().to(device)#1\n","        \n","        combined=torch.cat((category,input),2)\n","        output,hidden=self.rnn(combined)\n","        output=self.fc(output.reshape(len(output),-1))\n","        output=self.dropout(output)\n","\n","        # ********** END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE) *********** #\n","        return output, hidden\n","    \n","    def _init_hidden(self):\n","        return torch.zeros(self.num_layers, 1, self.hidden_size)"]},{"cell_type":"markdown","metadata":{"id":"jVTqo_xY_6Xv"},"source":["# 3. Training"]},{"cell_type":"markdown","metadata":{"id":"1Nmvkz0K_9PI"},"source":["### 3.1. Preparing for Training\n","\n","* Helper functions to get random pairs of (category, line)"]},{"cell_type":"code","execution_count":132,"metadata":{"id":"lAYJIm-P6O8s","executionInfo":{"status":"ok","timestamp":1669016338944,"user_tz":-540,"elapsed":18,"user":{"displayName":"김보민","userId":"10678150510375534256"}}},"outputs":[],"source":["# random item from a list\n","def random_choice(lst):\n","    return lst[random.randint(0, len(lst)-1)]\n","\n","# get a random category and random line from that category\n","def random_training_pair(all_categories, category_lines):\n","    category = random_choice(all_categories)\n","    line = random_choice(category_lines[category])\n","    # print(category,line)\n","    return category, line"]},{"cell_type":"markdown","metadata":{"id":"847R_HFsAtQ1"},"source":["* For each timestep (that is, for each letter in a training word) the inputs of the network will be (```category```, ```current letter```, ```hidden state```) and the outputs will be (```next letter```, ```next hidden state```). So for each training set, we'll need the category, a set of input letters, and a set of output/target letters.\n","\n","* Since we are predicting the next letter from the current letter for each timestep, the letter pairs are groups of consecutive letters from the line - e.g. for ```\"ABCD<EOS>\"``` we would create (\"A\", \"B\"), (\"B\", \"C\"), (\"C\", \"D\"), (\"D\", \"EOS\").\n","\n","![link text](https://i.imgur.com/JH58tXY.png)\n","\n","* The category tensor is a one-hot tensor of size ```<1 x n_categories>```. When training we feed it to the network at every timstep."]},{"cell_type":"markdown","source":["* **Q.2**: 3 points (1 point each)"],"metadata":{"id":"eBEs2tBvPSof"}},{"cell_type":"code","execution_count":133,"metadata":{"id":"IknXW2B_Arui","executionInfo":{"status":"ok","timestamp":1669016338944,"user_tz":-540,"elapsed":17,"user":{"displayName":"김보민","userId":"10678150510375534256"}}},"outputs":[],"source":["# One-hot matrix for category\n","def category_tensor(category, line_length, n_categories):\n","    tensor = torch.zeros(line_length, 1, n_categories)\n","    ################################################################################\n","    # TODO: implement a function that takes as input a string (category value), the#\n","    # length of a line, the number of categories and convert the category value    #\n","    # into a one-hot matrix of size (line_length, 1, n_categories). For example, if#\n","    # the input is \"Arabic\", then the output is [[1, 0, ..., 0], [1, 0, ..., 0], ..#\n","    # .., [1, 0, ..., 0]]. All row vectors are the same, and all the values of each#\n","    # row vector are zero except i'th position, where i is the index of \"Arabic\" in#\n","    # all_categories variable. Since the index of \"Arabic\" in the all_categories   #\n","    # is 0, only the 0'th element of each row vector is one.                       #\n","    ################################################################################\n","    li = all_categories.index(category)\n","    for v in tensor:\n","        v[0][li] = 1\n","    # ************ END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE) ************* #\n","    return tensor\n","\n","# One-hot matrix of first to last letters (not including EOS) for input\n","def input_tensor(line, line_length, n_letters):\n","    tensor = torch.zeros(line_length, 1, n_letters)\n","    ################################################################################\n","    # TODO: implement a function that takes as input a string (line; a single last #\n","    # name) and convert it into a one-hot matrix of size (len(line), 1, n_letters).#\n","    # For example, if the input is \"abc\", then the output should be [[1, 0, 0, ...]#\n","    # , [0, 1, 0, ...], [0, 0, 1, 0, ...]].                                        #\n","    ################################################################################\n","    for idx,v in enumerate(tensor):\n","        v[0][all_letters.find(line[idx])] = 1\n","    # ************ END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE) ************* #\n","    return tensor\n","\n","# LongTensor of second letter to end (EOS) for target\n","def target_tensor(line, line_length, n_letters):\n","    ################################################################################\n","    # TODO: implement a function that intakes a string (line; the last name) and   #\n","    # convert ecah chracter in the string from the second element (index==1) into  #\n","    # the index that points the location of the same character in the all_letters  #\n","    # variable. For example, if the input is \"abc\", then the output should be      #\n","    # [1, 2, n_letters-1]. Since we convert the character from the second (not the #\n","    # first) element, the index of \"a\" (0) is not included in the list. Note that  #\n","    # you MUST add the number (=n_letters-1) at the back of the list, which        #\n","    # indicates the End of Sentence (EOS). Please refer to the figure above.       #\n","    ################################################################################\n","    letter_indices=[all_letters.find(line[li]) for li in range(1,line_length)]\n","    letter_indices.append(n_letters-1)\n","    # ************ END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE) ************* #\n","    return torch.LongTensor(letter_indices)"]},{"cell_type":"markdown","source":["* **Q.3**: 1 point"],"metadata":{"id":"m0VetgmTPt5n"}},{"cell_type":"code","execution_count":134,"metadata":{"id":"HRth9HwmDmWB","executionInfo":{"status":"ok","timestamp":1669016338945,"user_tz":-540,"elapsed":17,"user":{"displayName":"김보민","userId":"10678150510375534256"}}},"outputs":[],"source":["# Make category, input, and target tensors from a random category, line pair\n","def random_sample(all_categories, category_lines, n_categories, n_letters):\n","    ##########################################################################\n","    # TODO: implement a sampling function. This function (1) randomly sample #\n","    # a training pair (category, line), (2) convert the category into one-hot#\n","    # matrix, (3) convert the line into one-hot matrix (the input tensor),   #\n","    # and (4) convert the line into a 1d vector of indices (the ground truth #\n","    # tensor). Plese use the implemented functions (random_training_pair,    #\n","    # category_tensor, input_tensor, target_tensor).                         #\n","    ##########################################################################\n","    category,line=random_training_pair(all_categories,category_lines)\n","    line_length=len(line)\n","    category_t=category_tensor(category,line_length, n_categories)\n","    input_line_t=input_tensor(line,line_length,n_letters)\n","    target_line_t=target_tensor(line,line_length,n_letters)\n","\n","    # ********* END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE) ********** #\n","    return category_t, input_line_t, target_line_t"]},{"cell_type":"markdown","metadata":{"id":"vXQUTFSpFah6"},"source":["### 3.2. Training the Network\n","\n","* In contrast to classification, where only the last output is used, we are making a prediction at every step, so we are calculating loss at every step."]},{"cell_type":"markdown","source":["* **Q.4**: 1 point"],"metadata":{"id":"KJ6NZ2VAPy-r"}},{"cell_type":"code","execution_count":135,"metadata":{"id":"rnEeuuR7FXuC","executionInfo":{"status":"ok","timestamp":1669016338945,"user_tz":-540,"elapsed":17,"user":{"displayName":"김보민","userId":"10678150510375534256"}}},"outputs":[],"source":["def train(model, all_categories, category_lines, epochs, lr, log_every):\n","    # set seed\n","    torch.manual_seed(444)\n","    # ship to cuda\n","    model.to(device)\n","    # loss\n","    loss_fn = nn.CrossEntropyLoss()\n","    # optimizer\n","    optim = torch.optim.Adam(model.parameters(), lr=lr)\n","\n","    # step function\n","    def one_step(category_t, input_line_t, target_line_t):\n","        ##########################################################################\n","        # TODO: implement a step function. You're answer MUST include all of the #\n","        # following:                                                             #\n","        #     (1) forward propagate                                              #\n","        #     (2) compute cross-entropy loss                                     #\n","        #     (3) set all gradients zero                                         #\n","        #     (4) backward propagate                                             #\n","        #     (5) update parameters                                              #\n","        ##########################################################################\n","        \n","        output,hidden=model(category_t,input_line_t) #1\n","        loss=loss_fn(output,target_line_t) #2\n","        optim.zero_grad() #3\n","        loss.backward() #4 \n","        optim.step() #5\n","        \n","        # ********* END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE) ********** #\n","        return loss.item()\n","    \n","    current_loss, losses = 0, []\n","\n","    # main loop\n","    for e in tqdm(range(1, epochs+1)):\n","        # get sample data\n","        category_t, input_line_t, target_line_t = random_sample(\n","            all_categories, category_lines, n_categories, n_letters\n","        )\n","        # ship to cuda\n","        category_t = category_t.to(device)\n","        input_line_t = input_line_t.to(device)\n","        target_line_t = target_line_t.to(device)\n","        # one step forward & backward\n","        loss = one_step(category_t, input_line_t, target_line_t)\n","        # acuumulate loss\n","        current_loss += loss\n","        if e % log_every == 0:\n","            current_loss /= log_every\n","            print(f\"Epoch: {e}/{epochs}, Loss; {current_loss:.4f}\")\n","            losses.append(current_loss)\n","            current_loss = 0\n","    \n","    return losses"]},{"cell_type":"code","execution_count":136,"metadata":{"id":"vNkKrqRnel6r","executionInfo":{"status":"ok","timestamp":1669016338945,"user_tz":-540,"elapsed":16,"user":{"displayName":"김보민","userId":"10678150510375534256"}}},"outputs":[],"source":["hidden_size = 128\n","input_size = n_categories + n_letters\n","rnn = RNN(input_size=input_size, hidden_size=hidden_size, num_layers=1, output_size=n_letters)"]},{"cell_type":"code","execution_count":137,"metadata":{"id":"GtcKE4VyNYts","outputId":"a970a8e5-8520-4f19-f784-b9bb678708cb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669016548205,"user_tz":-540,"elapsed":209275,"user":{"displayName":"김보민","userId":"10678150510375534256"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["  5%|▌         | 5097/100000 [00:10<03:01, 521.88it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 5000/100000, Loss; 3.2164\n"]},{"output_type":"stream","name":"stderr","text":[" 10%|█         | 10055/100000 [00:20<02:59, 500.78it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 10000/100000, Loss; 2.8656\n"]},{"output_type":"stream","name":"stderr","text":[" 15%|█▌        | 15059/100000 [00:29<02:49, 501.99it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 15000/100000, Loss; 2.8114\n"]},{"output_type":"stream","name":"stderr","text":[" 20%|██        | 20098/100000 [00:39<02:38, 505.48it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 20000/100000, Loss; 2.7284\n"]},{"output_type":"stream","name":"stderr","text":[" 25%|██▌       | 25069/100000 [00:50<02:24, 517.74it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 25000/100000, Loss; 2.6581\n"]},{"output_type":"stream","name":"stderr","text":[" 30%|███       | 30104/100000 [01:01<02:16, 510.45it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 30000/100000, Loss; 2.6201\n"]},{"output_type":"stream","name":"stderr","text":[" 35%|███▌      | 35094/100000 [01:15<02:23, 452.25it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 35000/100000, Loss; 2.5931\n"]},{"output_type":"stream","name":"stderr","text":[" 40%|████      | 40000/100000 [01:27<02:23, 417.36it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 40000/100000, Loss; 2.5643\n"]},{"output_type":"stream","name":"stderr","text":[" 45%|████▌     | 45030/100000 [01:38<01:58, 462.93it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 45000/100000, Loss; 2.5511\n"]},{"output_type":"stream","name":"stderr","text":[" 50%|█████     | 50090/100000 [01:48<01:35, 522.84it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 50000/100000, Loss; 2.5246\n"]},{"output_type":"stream","name":"stderr","text":[" 55%|█████▌    | 55087/100000 [01:58<01:28, 508.21it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 55000/100000, Loss; 2.5122\n"]},{"output_type":"stream","name":"stderr","text":[" 60%|██████    | 60056/100000 [02:08<01:17, 514.12it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 60000/100000, Loss; 2.5093\n"]},{"output_type":"stream","name":"stderr","text":[" 65%|██████▌   | 65054/100000 [02:19<01:09, 502.56it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 65000/100000, Loss; 2.4839\n"]},{"output_type":"stream","name":"stderr","text":[" 70%|███████   | 70060/100000 [02:29<00:57, 521.72it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 70000/100000, Loss; 2.4836\n"]},{"output_type":"stream","name":"stderr","text":[" 75%|███████▌  | 75076/100000 [02:39<00:48, 515.91it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 75000/100000, Loss; 2.4767\n"]},{"output_type":"stream","name":"stderr","text":[" 80%|████████  | 80064/100000 [02:49<00:39, 499.95it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 80000/100000, Loss; 2.4718\n"]},{"output_type":"stream","name":"stderr","text":[" 85%|████████▌ | 85070/100000 [02:59<00:29, 513.95it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 85000/100000, Loss; 2.4653\n"]},{"output_type":"stream","name":"stderr","text":[" 90%|█████████ | 90066/100000 [03:09<00:19, 516.14it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 90000/100000, Loss; 2.4762\n"]},{"output_type":"stream","name":"stderr","text":[" 95%|█████████▌| 95066/100000 [03:19<00:09, 512.15it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 95000/100000, Loss; 2.4592\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 100000/100000 [03:29<00:00, 477.78it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 100000/100000, Loss; 2.4476\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["losses = train(rnn, all_categories, category_lines, epochs=100000, lr=4e-5, log_every=5000)"]},{"cell_type":"code","execution_count":138,"metadata":{"id":"hEh4urfCNYtt","executionInfo":{"status":"ok","timestamp":1669016548781,"user_tz":-540,"elapsed":602,"user":{"displayName":"김보민","userId":"10678150510375534256"}},"colab":{"base_uri":"https://localhost:8080/","height":283},"outputId":"a46d7edf-5211-45a8-b6b6-09cee2112fc3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f171e5c4110>]"]},"metadata":{},"execution_count":138},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["plt.plot(losses)"]},{"cell_type":"markdown","metadata":{"id":"n7oZBkCBBSFh"},"source":["# 4. Sampling the Network\n","\n","To generate a word we give the networka letter and ask what the next one is, feed that in as the next letter, and repeat until the EOS token.\n","\n","* Create tensors for input category, starting letter, and empty hidden state\n","* Create a string ```output_name``` with the starting letter\n","* **Q.5** (2 points): Up to a maximum output length (**you shoud implement from here**)\n","    1. Feed the current letter to the network\n","    2. Get the next letter from highest output, and next hidden state.\n","    3. If the letter is EOS, stop here\n","    4. If a regular letter, add to ```output_name``` and continue.\n","* Return the final name"]},{"cell_type":"code","execution_count":139,"metadata":{"id":"rQC7qDKoBWie","executionInfo":{"status":"ok","timestamp":1669016548783,"user_tz":-540,"elapsed":18,"user":{"displayName":"김보민","userId":"10678150510375534256"}}},"outputs":[],"source":["def sample(model, category, start_letter):\n","    max_length = 20\n","    with torch.no_grad():\n","        category_t = category_tensor(category, len(start_letter), n_categories)\n","        input_t = input_tensor(start_letter, len(start_letter), n_letters)\n","        hidden = model._init_hidden()\n","        output_name = start_letter\n","        for i in range(max_length):\n","            ############################################################################\n","            # TODO: implement a text generating function. Up to a maximum output length#\n","            #      (1) Feed the current letter to the network                          #\n","            #      (2) Get the next letter from highest output, and next hidden state  #\n","            #      (3) If the letter is EOS, stop here                                 #\n","            #      (4) If a regular letter, add to output_name and continue            #\n","            ############################################################################\n","            output,hidden=model(category_t,input_t,hidden)\n","            v,i=output.topk(1)\n","            i=i[0,0]\n","            if i==n_letters-1:\n","                break\n","            output_name+=all_letters[i]\n","            category_t=category_tensor(category,len(output_name),n_categories)\n","            input_t=input_tensor(output_name,len(output_name),n_letters)\n","            # ********** END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE) *********** #\n","        return output_name\n","    \n","def samples(model, category, start_letters):\n","    for start_letter in start_letters:\n","        print(sample(model, category, start_letter))"]},{"cell_type":"code","execution_count":140,"metadata":{"id":"v2k1zwlNBWky","executionInfo":{"status":"ok","timestamp":1669016548783,"user_tz":-540,"elapsed":17,"user":{"displayName":"김보민","userId":"10678150510375534256"}}},"outputs":[],"source":["rnn = rnn.to('cpu')"]},{"cell_type":"code","execution_count":141,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1669016548784,"user":{"displayName":"김보민","userId":"10678150510375534256"},"user_tz":-540},"id":"RnPq8zolBWm9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2a0d70a7-b7d1-4019-c53b-766bcb2be773"},"outputs":[{"output_type":"stream","name":"stdout","text":["Rov\n","Uring\n","Shin\n","Chi\n","Han\n","In\n"]}],"source":["samples(rnn, 'Russian', 'RUS')\n","samples(rnn, 'Chinese', 'CHI')"]},{"cell_type":"code","execution_count":142,"metadata":{"id":"vzC39FJeNNeC","executionInfo":{"status":"ok","timestamp":1669016551702,"user_tz":-540,"elapsed":2929,"user":{"displayName":"김보민","userId":"10678150510375534256"}}},"outputs":[],"source":["drive.flush_and_unmount()"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.7.11 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.15"},"vscode":{"interpreter":{"hash":"d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"}}},"nbformat":4,"nbformat_minor":0}